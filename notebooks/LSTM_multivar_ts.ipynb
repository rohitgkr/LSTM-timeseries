{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LSTM to predict time series data using multivariate time series analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/price_ts.csv', parse_dates=True)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235   2023-07-17\n",
      "236   2023-07-18\n",
      "237   2023-07-19\n",
      "238   2023-07-20\n",
      "239   2023-07-21\n",
      "240   2023-07-24\n",
      "241   2023-07-25\n",
      "242   2023-07-26\n",
      "243   2023-07-27\n",
      "244   2023-07-28\n",
      "245   2023-07-31\n",
      "246   2023-08-01\n",
      "247   2023-08-02\n",
      "248   2023-08-03\n",
      "249   2023-08-04\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "train_dates = pd.to_datetime(df['Date'])\n",
    "print(train_dates.tail(15)) #Check last few dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'High', 'Low', 'Close', 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "cols = list(df)[1:6]\n",
    "print(cols) #['Open', 'High', 'Low', 'Close', 'Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.234974</td>\n",
       "      <td>59.937550</td>\n",
       "      <td>58.438721</td>\n",
       "      <td>58.688526</td>\n",
       "      <td>58.461750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.836845</td>\n",
       "      <td>59.398907</td>\n",
       "      <td>58.446526</td>\n",
       "      <td>58.493366</td>\n",
       "      <td>58.267342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.492584</td>\n",
       "      <td>60.733803</td>\n",
       "      <td>59.258392</td>\n",
       "      <td>60.218578</td>\n",
       "      <td>59.985889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.889931</td>\n",
       "      <td>61.834503</td>\n",
       "      <td>60.858704</td>\n",
       "      <td>61.592506</td>\n",
       "      <td>61.354507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.896957</td>\n",
       "      <td>62.427792</td>\n",
       "      <td>61.327087</td>\n",
       "      <td>62.396564</td>\n",
       "      <td>62.155453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>114.440002</td>\n",
       "      <td>114.750000</td>\n",
       "      <td>113.720001</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>114.239998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>113.690002</td>\n",
       "      <td>114.199997</td>\n",
       "      <td>112.269997</td>\n",
       "      <td>113.220001</td>\n",
       "      <td>113.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>112.970001</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>111.930000</td>\n",
       "      <td>111.970001</td>\n",
       "      <td>111.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>111.830002</td>\n",
       "      <td>113.169998</td>\n",
       "      <td>111.550003</td>\n",
       "      <td>112.360001</td>\n",
       "      <td>112.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>112.820000</td>\n",
       "      <td>113.870003</td>\n",
       "      <td>111.800003</td>\n",
       "      <td>113.059998</td>\n",
       "      <td>113.059998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open        High         Low       Close   Adj Close\n",
       "0     59.234974   59.937550   58.438721   58.688526   58.461750\n",
       "1     58.836845   59.398907   58.446526   58.493366   58.267342\n",
       "2     59.492584   60.733803   59.258392   60.218578   59.985889\n",
       "3     60.889931   61.834503   60.858704   61.592506   61.354507\n",
       "4     61.896957   62.427792   61.327087   62.396564   62.155453\n",
       "..          ...         ...         ...         ...         ...\n",
       "245  114.440002  114.750000  113.720001  114.239998  114.239998\n",
       "246  113.690002  114.199997  112.269997  113.220001  113.220001\n",
       "247  112.970001  113.500000  111.930000  111.970001  111.970001\n",
       "248  111.830002  113.169998  111.550003  112.360001  112.360001\n",
       "249  112.820000  113.870003  111.800003  113.059998  113.059998\n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training data - 5 columns\n",
    "df_for_training = df[cols].astype(float)            # convert all COLUMNs to float as they will store normalised values\n",
    "display(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06765007, -1.07855981, -1.07212694, -1.10397542, -1.10651941],\n",
       "       [-1.08735237, -1.10508348, -1.07173939, -1.113627  , -1.11610943],\n",
       "       [-1.05490167, -1.03935099, -1.03142693, -1.02830717, -1.03133466],\n",
       "       ...,\n",
       "       [ 1.59154721,  1.55894367,  1.58393278,  1.53104349,  1.53300662],\n",
       "       [ 1.53513183,  1.54269383,  1.56506438,  1.55033082,  1.55224506],\n",
       "       [ 1.58412408,  1.57716323,  1.5774779 ,  1.58494895,  1.58677544]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalize the values for sigmoid and tanh used in LSTM \n",
    "# normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n",
    "display(df_for_training_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape LSTM TS data \n",
    "For LSTM networks, we require to reshape an input data into ***n_samples x timesteps x n_features***. \n",
    "- timesteps => how much past data is considered as a step for every future prediction\n",
    "- n_features => how many features are used in training data for prediction output\n",
    "- n_samples => total # of training data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM TS data must be arranged as n_samples x (timesteps x n_features) where\n",
    "0 to timesteps-1 =>\n",
    "n_samples =>\n",
    " - 1st column displaying predicted_value (0-timesteps-1 => predicted_value = training value) \n",
    " - other columns are mutivariate features used for prediction & represent training features\n",
    " timestep =>\n",
    " This has the predicted output value in predicted_value column. This is for a future prediction window of 1. If predicting >1 look ahead in future (timestep: timestep+lookahead) indices will have the predicted_value\n",
    "\n",
    " (  &nbsp;&nbsp;&nbsp;&nbsp;look_back&nbsp;&nbsp;&nbsp;&nbsp;    +&nbsp;&nbsp;&nbsp;&nbsp;   look_ahead&nbsp;&nbsp;&nbsp;&nbsp;          +&nbsp;&nbsp;&nbsp;&nbsp;   next_look_back&nbsp;&nbsp;&nbsp;&nbsp;      +&nbsp;&nbsp;&nbsp;&nbsp;   next_look_ahead .....   )  \n",
    " (  &nbsp;&nbsp;&nbsp;&nbsp;past_value&nbsp;&nbsp;&nbsp;&nbsp; +&nbsp;&nbsp;&nbsp;&nbsp;      predicted_value&nbsp;&nbsp;&nbsp;&nbsp;     +&nbsp;&nbsp;&nbsp;&nbsp;   past_value&nbsp;&nbsp;&nbsp;&nbsp;          +&nbsp;&nbsp;&nbsp;&nbsp;   predicted_value ....   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 14  # Number of past days we want to use to predict the future.\n",
    "trainX = []     # training input vector\n",
    "trainY = []     # training output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "history = model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.1, verbose=1)\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out UK non working days\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday, nearest_workday\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "# Define the UK holiday calendar\n",
    "class UKHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        Holiday('New Year\\'s Day', month=1, day=1, observance=nearest_workday),\n",
    "        Holiday('Good Friday', month=1, day=1, offset=[pd.DateOffset(weekday=4)]),\n",
    "        Holiday('Easter Monday', month=1, day=1, offset=[pd.DateOffset(weekday=0)]),\n",
    "        Holiday('Early May Bank Holiday', month=5, day=1, offset=pd.DateOffset(weekday=0)),\n",
    "        Holiday('Spring Bank Holiday', month=5, day=31, offset=pd.DateOffset(weekday=0)),\n",
    "        Holiday('Summer Bank Holiday', month=8, day=31, offset=pd.DateOffset(weekday=0)),\n",
    "        Holiday('Christmas Day', month=12, day=25, observance=nearest_workday),\n",
    "        Holiday('Boxing Day', month=12, day=26, observance=nearest_workday)\n",
    "    ]\n",
    "uk_business_day = CustomBusinessDay(calendar=UKHolidayCalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 16\n",
    "n_days_for_prediction=15\n",
    "predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq=uk_business_day).tolist()\n",
    "prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "prediction_copies = np.repeat(prediction, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasted data snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to date value\n",
    "forecast_dates = []\n",
    "for time_i in predict_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "    \n",
    "df_fore = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n",
    "df_fore['Date']=pd.to_datetime(df_fore['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df[['Date', 'Open']]\n",
    "df_org['Date']=pd.to_datetime(df_org['Date'])\n",
    "df_org = df_org.loc[df_org['Date'] >= '2020-5-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Original vs Forecasted\n",
    "sns.lineplot(df_org['Date'], df_org['Open'])\n",
    "sns.lineplot(df_fore['Date'], df_fore['Open'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
